# is the more accurate is the expected value.
exp.function <- function(x) {
# We create a die
die <- 1:6
# We take a sample, which size is define by user.
mysample <- sample(x = die, size = x, replace=TRUE)
# We perform calculation given in a task on a vector.
Y <- mysample*2-1
# We return the mean of the calculated vector to get an expected value.
return(mean(Y))
}
# Testing the function for 1000 rolls.
exp.function(1000)
# 2.2     Monte Carlo integration
# 2.2.1.1 Tasks
# Expectation of continous uniformly distributed variable is calculated as E(x)=1/2*(a+b),
# where a and b are minimum and maximum values of the interval, respectively
# therefore, expectation of U is
# E(U) = 1/2*(0+1) = 1/2
# E(g(U)) = 1/2*(-1+1) = 0
# Alternative solution using calculation in R:
# We create a continous variable on the interval between 0 and 1. To do this
# we use the function seq with very small interval.
continous <- 0.0000001
population <- seq(0, 1, by = continous)
# To get expected value we calculate a mean of a population that we created.
# Expected value lies in the middle and is equal to 0.5
mean(population)
# To calculate E(g(U)) we perform a function g(x) = 2*x-1 on our population
result.vector <- population*2-1
# Expected value is the mean of calculated vector
mean(result.vector)
#   2.2.2  Main task
# Solution 1
my.calc.monte.carlo.step1 <- function(fun, n.draws) {
montecarlo <- fun(runif(n.draws, 0,1)) # uniform draws from the specified range as input for our function
result <- mean(montecarlo) # calculating the mean of those draws
return(result) } # this works because the integral is E[h(U)]
# Testing Solution 1
my.calc.monte.carlo.step1(fun=my.fun, n.draws = 1000)
# Solution 2
# Here the integral is calculated by throwing "darts" on the range/area we want to integrate
# For this, we have to define the area in question, throw the darts and count those,
# that are under/over f(x) (f(x) can be positive/negative).
my.calc.monte.carlo.step1.alt <- function(fun, n.draws) {
ymin <- min(fun(seq(from=0, to=1, by=0.01))) #gives the min y-value for target area
ymax <- max(fun(seq(from=0, to=1, by=0.01))) #gives the max y-value for target area
xdarts <-runif(n.draws,0,1) # random univariate x-values for darts
ydarts <- runif(n.draws, ymin, ymax) # random univariate y-values for darts
pos.darts <- sum(fun(xdarts) > ydarts & ydarts >= 0) # counts the positive darts
neg.darts <- sum(fun(xdarts) < ydarts & ydarts <= 0) # counts the negative darts
net.darts <- pos.darts-neg.darts # gives the net number of darts that count towards integral
target.area <- (1-0)*(ymax-ymin) # calculates size of target area
integral <- (net.darts/n.draws) * target.area # final calculation of the integral
return(integral)
}
# Testing Solution 2
my.calc.monte.carlo.step1.alt(my.fun, 1000)
# 2.2.3   Extension
# Solution 1
# This is essentially the same function as in 2.2.2
my.calc.monte.carlo <- function(fun, my.range, n.draws) {
montecarlo <- fun(runif(n.draws, my.range[1], my.range[2])) # my.range[] allows for dynamic range input
# Because the intervall can now be different from 1 we need
# to adjust again using my.range[] to get the actual range input for multiplication
result <- mean(montecarlo)*my.range[2]-my.range[1]
return(result)
}
# Testing Solution 1
my.calc.monte.carlo(fun=my.fun, my.range = c(0,2), n.draws = 1000)
my.calc.monte.carlo(fun=my.fun, my.range = c(0,2), n.draws = 10000)
# Solution 2
my.calc.monte.carlo.alt <- function(fun, n.draws, my.range=c(0,1)) {
ymin <- min(fun(seq(from=my.range[1], to=my.range[2], by=0.01))) #gives the min y-value for target area
ymax <- max(fun(seq(from=my.range[1], to=my.range[2], by=0.01))) #gives the max y-value for target area
xdarts <-runif(n.draws,my.range[1],my.range[2]) # random univariate x-values for darts
ydarts <- runif(n.draws, ymin, ymax) # random univariate y-values for darts
pos.darts <- sum(fun(xdarts) > ydarts & ydarts >= 0) # counts the positive darts
neg.darts <- sum(fun(xdarts) < ydarts & ydarts <= 0) # counts the negative darts
net.darts <- pos.darts-neg.darts # gives the net number of darts that count towards integral
target.area <- (my.range[2]-my.range[1])*(ymax-ymin) # calculates size of target area
integral.fin <- net.darts/n.draws * target.area # final calculation of the integral
return(integral.fin)
}
# Testing Solution 2
my.calc.monte.carlo.alt(fun = my.fun, n.draws = 1000, my.range = c(0,2))
# 3 Third Part: Binary to decimal
my.calc.monte.carlo.alt(fun = my.fun, n.draws = 1000, my.range = c(0,2))
my.fun3 <- function(x) {
return(x^3)
}
my.calc.monte.carlo(fun=my.fun, my.range = c(0,2), n.draws = 1000)
my.calc.monte.carlo(fun=my.fun, my.range = c(0,2), n.draws = 10000)
my.fun(x) <- function {
return(x^2)
my.fun(x) <- function (){
return(x^2)
}
my.fun(x) <- function (){
return(x^2)
}
my.fun() <- function (x){
my.fun <- function (x){
return(x^2)
}
}
my.fun <- function (x){
return(x^2)
}
my.calc.monte.carlo(fun=my.fun, my.range = c(0,2), n.draws = 1000)
my.calc.monte.carlo(fun=my.fun, my.range = c(0,2), n.draws = 10000)
my.fun <- function (x){
return(x)
}
# Testing Solution 1
my.calc.monte.carlo(fun=my.fun, my.range = c(0,2), n.draws = 1000)
my.calc.monte.carlo(fun=my.fun, my.range = c(0,2), n.draws = 10000)
my.calc.monte.carlo(fun=my.fun, my.range = c(0,2), n.draws = 1000)
my.calc.monte.carlo(fun=my.fun, my.range = c(0,2), n.draws = 10000)
# Solution 2
my.calc.monte.carlo.alt <- function(fun, n.draws, my.range=c(0,1)) {
ymin <- min(fun(seq(from=my.range[1], to=my.range[2], by=0.01))) #gives the min y-value for target area
ymax <- max(fun(seq(from=my.range[1], to=my.range[2], by=0.01))) #gives the max y-value for target area
xdarts <-runif(n.draws,my.range[1],my.range[2]) # random univariate x-values for darts
ydarts <- runif(n.draws, ymin, ymax) # random univariate y-values for darts
pos.darts <- sum(fun(xdarts) > ydarts & ydarts >= 0) # counts the positive darts
neg.darts <- sum(fun(xdarts) < ydarts & ydarts <= 0) # counts the negative darts
net.darts <- pos.darts-neg.darts # gives the net number of darts that count towards integral
target.area <- (my.range[2]-my.range[1])*(ymax-ymin) # calculates size of target area
integral.fin <- net.darts/n.draws * target.area # final calculation of the integral
return(integral.fin)
}
# Testing Solution 2
my.calc.monte.carlo.alt(fun = my.fun, n.draws = 1000, my.range = c(0,2))
# 3 Third Part: Binary to decimal
# We create a function which takes a binary number as an input and convert it
# to decimal.
binary.to.dec <- function(x) {
# First we have to split the number to a vector of digits. In order to do that
# we use the function as.character and then we are able to split the vector to
# seperate digits. At the end we have to convert it back to numeric vector.
split <- as.numeric(strsplit(as.character(x), "")[[1]])
result <- c()
# We use the loop to perform a calculation for each digit
for(i in 1:length(split)) {
number <- split[(length(split))-i+1]*2^(i-1)
# Each time we add the value to an empty vector that we created at the beginning
result[i] <- number
}
# Final value is a sum of all numbers saved in a result vector.
return(sum(result))
}
# Testing the function
binary.to.dec(1011)
binary.to.dec(1)
binary.to.dec(10)
binary.to.dec(0101)
EV <- function(roll=20, n){
#Define a die as an array from 1 to 6.
die = 1:6
#Define the probability of a die. Each side is observed with equal probability 1/6.
p.die = rep(1/6, 6)
g = die*2-1
EV = c()
for (i in 1:roll) {
#add the value of each roll to the vectors
EV = append(EV, sum(sample(g, size=n, prob=p.die, replace=T))/n)
}
return(round(mean(EV),3))
}
EV(20,1000)
EV(1,1000)
EV(0,1000)
EV(0,0)
EV(0,1)
EV(0,1)
EV(0,1)
EV(0,1)
EV(0,1)
EV(0,1)
EV(0,1)
EV(0,1)
EV(0,1)
EV(0,1)
EV(0,999999)
Breite = c(39, 42, 44, 44, 35, 31, 43)
Mortalität = c(200, 128, 117, 129, 182, 229, 134)
mean(Breite)
mean(Mortalität)
mean(Breite*Mortalität)
var(Breite^2)
var(Breite)^2
var(Breite)^2  - var(Breite^2)
mean(Breite*Mortalität) - mean(Breite) * mean(Mortalität) /(var(Breite)^2  - var(Breite^2))
(mean(Breite*Mortalität) - mean(Breite) * mean(Mortalität) )/(var(Breite)^2  - var(Breite^2))
(mean(Breite*Mortalität) - mean(Breite) * mean(Mortalität) )/( var(Breite^2) - var(Breite)^2 )
Breite = c(39, 42, 44, 44, 35, 31, 43)
Mortalität = c(200, 128, 117, 129, 182, 229, 134)
Regression <- lm(Mortalität ~ Breite)
summary(Regression)
plot(Breite, Mortalität)
abline(Regression)
points(40, 40 * -7.986 + 477.009, col="red")
40 * -7.986 + 477.009
matrix = matrix(c(5,7,3,6,2,4,6,4), byrow = TRUE, nrow = 2)
matrix
K = matrix %*% matrix
K = matrix %*% t(matrix)
K
K = t(matrix) %*% (matrix)
K
y = matrix(c(1,1,-1,-1), byrow = TRUE)
y
y = matrix(c(1,1,-1,-1), byrow = TRUE, nrow = 1)
y
y = matrix(c(1,1,-1,-1), byrow = TRUE)
y
x = rbind(100)
x
x = rbinom(100)
x
x = rbinom(100)
x = rbinom(100,2,0.5)
x
x = rbinom(100,1,0.5)
x
x = rbinom(100,1,0.5) + 0.5
x = rbinom(1000,1,0.5) + 0.5
x
p = prod(x)
p
N = 1000
res = c()
for (i in 1:N) {
x = rbinom(100,1,0.5) + 0.5
p = prod(x)
res = c(res,p)
}
res
mean(res)
N = 10000
res = c()
for (i in 1:N) {
x = rbinom(100,1,0.5) + 0.5
p = prod(x)
res = c(res,p)
}
res
median(res)
plot(density(res))
x = rbinom(100,1,0.5) + 0.5
x
N = 10000
res = c()
for (i in 1:N) {
x = rbinom(10,1,0.5) + 0.5
p = prod(x)
res = c(res,p)
}
res
plot(res)
plot(density(res))
N = 100000
res = c()
for (i in 1:N) {
x = rbinom(10,1,0.5) + 0.5
p = prod(x)
res = c(res,p)
}
res
median(res)
N = 100000
res = c()
for (i in 1:N) {
x = rbinom(100,1,0.5) + 0.5
p = prod(x)
res = c(res,p)
}
res
median(res)
plot(res)
plot(density(res))
res
median(res)
plot(res)
x1 = c(1,2,3)
x2 = c(11,12,13)
plot(x1,x2)
-0.2 * x2 + 1,2 * x1
-0.2 * x2 + 1.2 * x1
+0.2 * x2 - 1.2 * x1
plot(x1,x2)
2.3 * x1 -0.3 * x2
2.3 * x1 - 0.3 * x2
+0.2 * x2 - 1.2 * x1
- .3 * x1 + 2.3 * x2
2.3 * x1 - 0.3 * x2
abine(a = 0, b = .130434783)
abline(a = 0, b = .130434783)
2.3 * x1 - 0.3 * x2
- .3 * x1 + 2.3 * x2
abline(a = 0, b = 7.666)
abline(a = 0, b = 6)
x1 = c(2,2,2)
x2 = c(11,12,13)
plot(x1,x2)
-0.115 * x1 + 2 * x2
-0.115 * x2 + 2 * x1
x1 = c(1,20,29)
x2 = c(1,2,3)
plot(x1,x2)
x1 = c(1,20,29)
x2 = c(1,2,3)
plot(x1,x2)
0.235 * x2 - 1.24 * x1
0.235 * x1 - 1.24 * x2
abline(a = 0, b = 5.258)
abline(a = 0, b = 0.19)
x1 = c(1,20,29)
x2 = c(1,2,3)
plot(x1,x2)
0.235 * x1 - 1.24 * x2
abline(a = 0, b = 7.666)
abline(a = 0, b = 0.19)
0.235 * x1 - 1.24 * x2
abline(a = 0, b = 7.666)
abline(a = 0, b = 0.19)
x1 = c(1-1,2)
x2 = c(1,2,3)
plot(x1,x1)
-0.5 * x1 - 0.5 * x1
x1 = c(1,-1,2)
x2 = c(1,2,3)
plot(x1,x1)
-0.5 * x1 - 0.5 * x1
abline(a = 0, b = 1)
abline(a = 0, b = -1)
x1 = c(1,-1,2)
x2 = c(1,2,3)
plot(x1,x1)
-0.5 * x1 - 0.5 * x1
abline(a = 0, b = -1)
abline(a = 0, b = 0.19)
x1 = c(1,-1,2)
x2 = c(1,2,3)
plot(x1,x1)
-0.5 * x1 - 0.5 * x1
abline(a = 0, b = -1)
x1 = c(1,-1,2) + 4
x2 = c(1,2,3)
plot(x1,x1)
-0.5 * x1 - 0.5 * x1
abline(a = 0, b = -1)
x1 = c(1,-1,2) + 4
x2 = c(1,2,3)
plot(x1,x1)
-0.5 * x1 - 0.5 * x1
abline(a = 0, b = -1)
x1 = c(1,-1,2)
x2 = c(1,2,3)
plot(x1,x1)
-0.5 * x1 - 0.5 * x1
abline(a = 0, b = -1)
x1 = c(1,-1,0)
x2 = c(1,-1,1)
plot(x1,x2)
0.00031 * x1 + 1 * x2
abline(a = 0, b = -0.0031)
x1 = c(1,-1,0)
x2 = c(1,-1,.5)
plot(x1,x2)
0.00031 * x1 + 1 * x2
abline(a = 0, b = -.00015)
x1 = c(1,-1,0)
x2 = c(1,-1,.1)
plot(x1,x2)
`change_Support_Vectors_2016.06.24.20:41:55_n=1000_replication=100_C=1_kernel=linear_data=.dataSimulation([0.8,.0.7,.0.9,..0.3],.error,.0,.n)` <- read.table("~/Dropbox/Eigene Dateien/Studium/SS 2016/Machine Learning/BootstrapingSVM/src/output/change_Support_Vectors_2016-06-24 20:41:55_n=1000_replication=100_C=1_kernel=linear_data= dataSimulation([0.8, 0.7, 0.9, -0.3], error, 0, n).txt", quote="\"", comment.char="")
View(`change_Support_Vectors_2016.06.24.20:41:55_n=1000_replication=100_C=1_kernel=linear_data=.dataSimulation([0.8,.0.7,.0.9,..0.3],.error,.0,.n)`)
read('change_Support_Vectors_2016.06.24.20:41:55_n=1000_replication=100_C=1_kernel=linear_data=.dataSimulation([0.8,.0.7,.0.9,..0.3],.error,.0,.n)')
read.table('change_Support_Vectors_2016.06.24.20:41:55_n=1000_replication=100_C=1_kernel=linear_data=.dataSimulation([0.8,.0.7,.0.9,..0.3],.error,.0,.n)')
`change_Support_Vectors_2016.06.24.20:41:55_n=1000_replication=100_C=1_kernel=linear_data=.dataSimulation([0.8,.0.7,.0.9,..0.3],.error,.0,.n)` <- read.table("~/Dropbox/Eigene Dateien/Studium/SS 2016/Machine Learning/BootstrapingSVM/src/output/change_Support_Vectors_2016-06-24 20:41:55_n=1000_replication=100_C=1_kernel=linear_data= dataSimulation([0.8, 0.7, 0.9, -0.3], error, 0, n).txt", quote="\"", comment.char="")
View(`change_Support_Vectors_2016.06.24.20:41:55_n=1000_replication=100_C=1_kernel=linear_data=.dataSimulation([0.8,.0.7,.0.9,..0.3],.error,.0,.n)`)
setwd("~/Dropbox/Eigene Dateien/Studium/SS 2016/Machine Learning/BootstrapingSVM/src/output")
read.table("./change_Support_Vectors_2016.06.24.20:41:55_n=1000_replication=100_C=1_kernel=linear_data=.dataSimulation([0.8,.0.7,.0.9,..0.3],.error,.0,.n)")
read.table("./test")
read.table("test")
read.table("test.txt")
read.table("test.txt")
x <- read.table("test.txt")
x
x[1,]
data <- read.table("test.txt")
x = data[1,]
y = data[2,]
type(x)
type(y)
x
plot(x,y)
scatter(x,y)
plot.scatter(x,y)
plot(c(1), 2)
plot.scatter(x[1], y[1])
scatter(x[1], y[1])
View(x)
x[1]
x[2]
len(x)
scatter(1,2)
scater(1,2)
plot(x)
x = c(data[1,])
plot(x)x
plot(x)
x
x = data[1,2]
y = data[2,3]
y = data[2,3]
x = c()
y = c()
for i in 1:20 {
x = c(x, data[1,i])
y = c(y, data[1,i])
}
data <- read.table("test.txt")
x = c()
y = c()
for (i in 1:20) {
x = c(x, data[1,i])
y = c(y, data[1,i])
}
scatter(x,y)
plot(x,y)
data <- read.table("test.txt")
x = c()
y = c()
for (i in 1:20) {
x = c(x, data[1,i])
y = c(y, data[2,i])
}
plot(x,y)
fit = lm(y ~ x)
abline(fit)
fit = lm(y ~ x, x*x)
fit = lm(y ~ x, x*x)
fit = lm(y ~ x + x*x)
plot(x,y)
abline(fit)
fit = lm(y ~ x + x*x)
summary(fit)
fit = lm(y ~ x + x*x)
summary(fit)
plot(x,y)
abline(fit)
fit = lm(y ~ x)
summary(fit)
plot(x,y)
abline(fit)
data <- read.table("test2.txt")
x = c()
y = c()
for (i in 1:40) {
x = c(x, data[1,i])
y = c(y, data[2,i])
}
fit = lm(y ~ x)
summary(fit)
plot(x,y)
abline(fit)
data <- read.table("test3.txt")
x = c()
y = c()
for (i in 1:50) {
x = c(x, data[1,i])
y = c(y, data[2,i])
}
fit = lm(y ~ x)
summary(fit)
plot(x,y)
abline(fit)
data <- read.table("test4.txt")
x = c()
y = c()
for (i in 1:40) {
x = c(x, data[1,i])
y = c(y, data[2,i])
}
fit = lm(y ~ x)
summary(fit)
plot(x,y)
abline(fit)
data <- read.table("test4.txt")
x = c()
y = c()
for (i in 1:40) {
x = c(x, data[1,i])
y = c(y, data[2,i])
}
fit = lm(y ~ x)
summary(fit)
plot(x,y)
abline(fit)
data <- read.table("test5.txt")
x = c()
y = c()
for (i in 1:40) {
x = c(x, data[1,i])
y = c(y, data[2,i])
}
fit = lm(y ~ x)
summary(fit)
plot(x,y)
abline(fit)
